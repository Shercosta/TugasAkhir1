{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Corpus Bahasa Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6507702\n"
     ]
    }
   ],
   "source": [
    "with open('wiki.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    # ✅ ['𝘈Ḇ𝖢𝕯٤ḞԍНǏ\\n', 'hello world']\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# build language model\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('wiki.txt', encoding='utf-8').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "    # selection mechanism\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "# candidate model\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "# error model\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maka'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('mrka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'kcing' -> 'kucing'\n",
      "'memkan' -> 'memakan'\n",
      "'mrdeka' -> 'merdeka'\n",
      "'mnyedihkan' -> 'menyedihkan'\n",
      "'gimna' -> 'gmina'\n",
      "'terdpt' -> 'terdpat'\n",
      "'mrmpersulit' -> 'mempersulit'\n",
      "'mhon' -> 'moon'\n",
      "'banos' -> 'banos'\n",
      "'begimana' -> 'bagimana'\n",
      "- Peter Norvig: 0.009091615676879883 detik\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "test_words = ['kcing', 'memkan', 'mrdeka', 'mnyedihkan', 'gimna',\n",
    "              'terdpt', 'mrmpersulit', 'mhon', 'banos', 'begimana']\n",
    "              \n",
    "start = time.time()\n",
    "for w in test_words:\n",
    "    print(f\"'{w}' -> '{correction(w)}'\")\n",
    "end = time.time()\n",
    "print(f'- Peter Norvig: {end-start} detik')\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75d7e97546f3f779c2f1c3987c73a9e3c88127590789d109a23ce07b21b1a428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
